{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### resize images so they are a uniform size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "from PIL import Image as img # image processing \n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil # for emptying file folders and not creaet duplicates\n",
    "import random\n",
    "import time\n",
    "import torchvision.transforms.v2 as transforms # transform images to create larger dataset\n",
    "import gc\n",
    "\n",
    "# set wd\n",
    "os.chdir('C:/Users/dalto/OneDrive/Pictures/Documents/Projects/Fracture/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder emptied successfully\n",
      "Folder emptied successfully\n",
      "Folder emptied succesfully\n"
     ]
    }
   ],
   "source": [
    "# empty folders to avoid duplicates as there has been a few iterations of naming schemes used\n",
    "shutil.rmtree('./images/fracture_resize')\n",
    "# recreate the empty directory\n",
    "os.makedirs('./images/fracture_resize')\n",
    "print(\"Folder emptied successfully\")\n",
    "\n",
    "shutil.rmtree('./images/non_fractured_resize')\n",
    "# recreate the empty directory\n",
    "os.makedirs('./images/non_fractured_resize')\n",
    "print(\"Folder emptied successfully\")\n",
    "\n",
    "shutil.rmtree('./images/resize_data') # empty resize data\n",
    "os.makedirs('./images/resize_data') # make folder\n",
    "print(\"Folder emptied succesfully\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# handle any open images data...\n",
    "gc.enable()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing IMG0004028.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004028.jpg\n",
      "Error processing IMG0004029.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004029.jpg\n",
      "Error processing IMG0004036.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004036.jpg\n",
      "Error processing IMG0004070.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004070.jpg\n",
      "Error processing IMG0004073.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004073.jpg\n",
      "Error processing IMG0004076.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004076.jpg\n",
      "Error processing IMG0004079.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004079.jpg\n",
      "Error processing IMG0004084.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004084.jpg\n",
      "Error processing IMG0004092.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004092.jpg\n",
      "Error processing IMG0004098.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004098.jpg\n",
      "Error processing IMG0004100.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004100.jpg\n",
      "Error processing IMG0004109.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004109.jpg\n",
      "Error processing IMG0004119.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004119.jpg\n",
      "Error processing IMG0004120.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004120.jpg\n",
      "Error processing IMG0004121.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004121.jpg\n",
      "Error processing IMG0004122.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004122.jpg\n",
      "Error processing IMG0004123.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004123.jpg\n",
      "Error processing IMG0004129.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004129.jpg\n",
      "Error processing IMG0004130.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004130.jpg\n",
      "Error processing IMG0004134.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004134.jpg\n",
      "Error processing IMG0004142.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004142.jpg\n",
      "Error processing IMG0004143.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004143.jpg\n",
      "Error processing IMG0004145.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004145.jpg\n",
      "Error processing IMG0004148.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004148.jpg\n",
      "Error processing IMG0004149.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004149.jpg\n",
      "Error processing IMG0004154.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004154.jpg\n",
      "Error processing IMG0004155.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004155.jpg\n",
      "Error processing IMG0004159.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004159.jpg\n",
      "Error processing IMG0004169.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004169.jpg\n",
      "Error processing IMG0004170.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004170.jpg\n",
      "Error processing IMG0004173.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004173.jpg\n",
      "Error processing IMG0004174.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004174.jpg\n",
      "Error processing IMG0004177.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004177.jpg\n",
      "Error processing IMG0004189.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004189.jpg\n",
      "Error processing IMG0004194.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004194.jpg\n",
      "Error processing IMG0004226.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004226.jpg\n",
      "Error processing IMG0004227.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004227.jpg\n",
      "Error processing IMG0004228.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004228.jpg\n",
      "Error processing IMG0004251.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004251.jpg\n",
      "Error processing IMG0004252.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004252.jpg\n",
      "Error processing IMG0004255.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004255.jpg\n",
      "Error processing IMG0004256.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004256.jpg\n",
      "Error processing IMG0004258.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004258.jpg\n",
      "Error processing IMG0004259.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004259.jpg\n",
      "Error processing IMG0004263.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004263.jpg\n",
      "Error processing IMG0004273.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004273.jpg\n",
      "Error processing IMG0004275.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004275.jpg\n",
      "Error processing IMG0004278.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004278.jpg\n",
      "Error processing IMG0004279.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004279.jpg\n",
      "Error processing IMG0004285.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004285.jpg\n",
      "Error processing IMG0004286.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004286.jpg\n",
      "Error processing IMG0004288.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004288.jpg\n",
      "Error processing IMG0004290.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004290.jpg\n",
      "Error processing IMG0004291.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004291.jpg\n",
      "Error processing IMG0004297.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004297.jpg\n",
      "Error processing IMG0004298.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004298.jpg\n",
      "Error processing IMG0004304.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004304.jpg\n",
      "Error processing IMG0004308.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004308.jpg\n",
      "Error processing IMG0004347.jpg, skipping...\n",
      "error ./images/original_data/Non_fractured\\IMG0004347.jpg\n"
     ]
    }
   ],
   "source": [
    "# Resize the images to 224x224, which is the most common size of images. \n",
    "# Images that are not this size also only have to downscale which is more optimal\n",
    "# Also added more details to the file name to make sure everyname was unqiue\n",
    "\n",
    "# function to resize\n",
    "def resize(imagePath, targetSize, save_folder, type):\n",
    "    # open and resize\n",
    "    image = img.open(imagePath)\n",
    "    image = image.resize(targetSize)\n",
    "    \n",
    "    # get base filename and add type to ensure unique file names\n",
    "    base_name = os.path.splitext(os.path.basename(imagePath))[0]  # get filename without extension\n",
    "    new_name = f\"{type}{random.randint(0,9999)}_{random.randint(0,9999)}.jpg\"  # Force .jpg extension\n",
    "    \n",
    "    # save the new image as JPG\n",
    "    save_path = os.path.join(save_folder, new_name)\n",
    "    image.save(save_path, 'JPEG')\n",
    "    \n",
    "\n",
    "# iterate over elements in folder | no need here, all images are fine\n",
    "for filename in os.listdir('./images/original_data/Fractured'):\n",
    "    file_path = os.path.join('./images/original_data/Fractured', filename)\n",
    "    resize(file_path, (224,224), './images/fracture_resize', \"frac\")\n",
    "\n",
    "# had to implement try and except because a few images were corrupted in this folder \n",
    "for filename in os.listdir('./images/original_data/Non_fractured'):\n",
    "    try:\n",
    "        file_path = os.path.join('./images/original_data/Non_fractured', filename)\n",
    "        resize(file_path, (224,224),'./images/non_fractured_resize', \"nfrac\")\n",
    "    except:\n",
    "        # if there's a file error, print the error and continue\n",
    "        print(f\"Error processing {filename}, skipping...\")\n",
    "        # delete the file\n",
    "        gc.collect() # hopefully clean mem\n",
    "        time.sleep(2)\n",
    "        try:\n",
    "            os.remove(file_path)\n",
    "        except:\n",
    "            print(f\"error {file_path}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images converted\n",
      "images converted\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageOps\n",
    "\n",
    "# images to greyscale, cnn only takes input of 1\n",
    "def convert_to_grayscale(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        image = img.open(file_path)\n",
    "        try: \n",
    "            # Check if image is RGB (3 channels)\n",
    "            if image.mode == 'RGB':\n",
    "                # Convert to grayscale\n",
    "                gray_image = ImageOps.grayscale(image)\n",
    "                # Save back to the same location\n",
    "                gray_image.save(file_path)\n",
    "        except:\n",
    "            print(f\"error for file {file_path}\")\n",
    "            continue\n",
    "\n",
    "    print('images converted') # completion\n",
    "\n",
    "# Convert images in both folders\n",
    "convert_to_grayscale('./images/fracture_resize')\n",
    "convert_to_grayscale('./images/non_fractured_resize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2795\n"
     ]
    }
   ],
   "source": [
    "# check diffrence to ensure file alignemnt in size so model is efficetively learning pattern\n",
    "inbalance = len(os.listdir('./images/fracture_resize')) - len(os.listdir('./images/non_fractured_resize'))\n",
    "print(inbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([ # add random crop \n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),  \n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.ScaleJitter(target_size=(224,224), scale_range=(0.8,1.2)),\n",
    "        transforms.ColorJitter(brightness=0.25, contrast=0.4, saturation=0.4, hue=0.1)\n",
    "\n",
    "    ])\n",
    "\n",
    "new_per_folder = 12000\n",
    "\n",
    "# make transforms to increase data amount\n",
    "for i in range(new_per_folder):\n",
    "    random_filename = random.choice(os.listdir('./images/fracture_resize'))\n",
    "    path = os.path.join('./images/fracture_resize', random_filename)\n",
    "\n",
    "    # Load and apply transformations\n",
    "    random_image = img.open(path)\n",
    "    transformed_image = transform(random_image)\n",
    "\n",
    "    # change filename to prevent conflicts\n",
    "    base_name = os.path.splitext(os.path.basename(path))[0]  # get filename without extension\n",
    "    extension = os.path.splitext(path)[1]  # get extension\n",
    "    new_path = f\"{base_name}_{i}alter{extension}\"\n",
    "    \n",
    "    # save image\n",
    "    try:\n",
    "        transformed_image.save(os.path.join('./images/fracture_resize', new_path))\n",
    "    except:\n",
    "        print(\"image skipped\")\n",
    "        continue\n",
    "\n",
    "for i in range(new_per_folder + inbalance):\n",
    "    random_filename = random.choice(os.listdir('./images/non_fractured_resize'))\n",
    "    path = os.path.join('./images/non_fractured_resize', random_filename)\n",
    "\n",
    "    # Load and apply transformations\n",
    "    random_image = img.open(path)\n",
    "    transformed_image = transform(random_image)\n",
    "\n",
    "    # change filename to prevent conflicts\n",
    "    base_name = os.path.splitext(os.path.basename(path))[0]  # get filename without extension\n",
    "    extension = os.path.splitext(path)[1]  # get extension\n",
    "    new_path = f\"{base_name}_{i}alter{extension}\"\n",
    "    \n",
    "    # save image\n",
    "    transformed_image.save(os.path.join('./images/non_fractured_resize', new_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert images in both folders to bmp type\n",
    "def convert_to_bmp(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.jpeg'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                # Open and convert image\n",
    "                image = img.open(file_path)\n",
    "                new_filename = os.path.splitext(filename)[0] + '.bmp'\n",
    "                new_path = os.path.join(folder_path, new_filename)\n",
    "                image.save(new_path, 'BMP')\n",
    "                # Remove original jpg file\n",
    "                os.remove(file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error converting {filename}: {e}\")\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"{file_path} skipped\") # if non jpeg files\n",
    "\n",
    "# Convert images in both folders\n",
    "convert_to_bmp('./images/fracture_resize')\n",
    "convert_to_bmp('./images/non_fractured_resize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a matching csv to prep for pytorch data loading\n",
    "data = {'name': [], 'class': []}\n",
    "\n",
    "# iterate over file names in fracture images\n",
    "for filename in os.listdir('./images/fracture_resize'):\n",
    "    data['name'].append(filename)\n",
    "    data['class'].append(1) # FRACTURE = 1\n",
    "\n",
    "for filename in os.listdir('./images/non_fractured_resize'):\n",
    "    data['name'].append(filename)\n",
    "    data['class'].append(0) # NO FRACTURE = 0\n",
    "\n",
    "# create dataframe\n",
    "class_id = pd.DataFrame(data)\n",
    "class_id.to_csv('./images/class_ids.csv', index=False) # note the slight class imbalance that potentially needs to be accounted for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new resize_data directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images in resize_data: 30868\n"
     ]
    }
   ],
   "source": [
    "# create a new directory for combined data\n",
    "try:\n",
    "    shutil.rmtree('./images/resize_data') # empty resize data\n",
    "    os.makedirs('./images/resize_data')\n",
    "    print(\"Created new resize_data directory\") \n",
    "except Exception as e:\n",
    "    os.makedirs('./images/resize_data', exist_ok=True)\n",
    "    print(\"Using existing resize_data directory\")\n",
    "\n",
    "# copy fracture images\n",
    "for img_file in os.listdir('./images/fracture_resize'):\n",
    "    src = os.path.join('./images/fracture_resize', img_file)\n",
    "    dst = os.path.join('./images/resize_data', img_file)\n",
    "    if os.path.exists(src):  # Check if the source file exists\n",
    "        shutil.copy2(src, dst)\n",
    "# copy non-fracture images\n",
    "for img_file in os.listdir('./images/non_fractured_resize'):\n",
    "    src = os.path.join('./images/non_fractured_resize', img_file)\n",
    "    dst = os.path.join('./images/resize_data', img_file)\n",
    "    if os.path.exists(src):  # Check if the source file exists\n",
    "        shutil.copy2(src, dst)\n",
    "    else:\n",
    "        print(f\"Source file not found: {src}\")\n",
    "    src = os.path.join('./images/non_fractured_resize', img_file)\n",
    "    dst = os.path.join('./images/resize_data', img_file)\n",
    "    shutil.copy2(src, dst)\n",
    "\n",
    "print(f\"Total images in resize_data: {len(os.listdir('./images/resize_data'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of corrupted files removed: 0\n"
     ]
    }
   ],
   "source": [
    "# Test for corrupted images and remove them\n",
    "corrupted_files = []\n",
    "\n",
    "for filename in os.listdir('./images/resize_data'):\n",
    "    file_path = os.path.join('./images/resize_data', filename)\n",
    "    try:\n",
    "        # Try to open the image\n",
    "        with img.open(file_path) as image:\n",
    "            # Try to load the image data\n",
    "            image.verify()\n",
    "            image.close()\n",
    "            \n",
    "            # Double check by trying to load it again\n",
    "            image = img.open(file_path)\n",
    "            image.load()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Corrupted file found: {filename}\")\n",
    "        corrupted_files.append(filename)\n",
    "        # Remove the corrupted file\n",
    "        os.remove(file_path)\n",
    "        \n",
    "        # Also remove it from the class_id DataFrame if it exists\n",
    "        class_id = class_id[class_id['name'] != filename]\n",
    "\n",
    "print(f\"Number of corrupted files removed: {len(corrupted_files)}\")\n",
    "if corrupted_files:\n",
    "    print(\"Corrupted files:\", corrupted_files)\n",
    "    # Save updated class_id DataFrame\n",
    "    class_id.to_csv('./images/class_ids.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
