{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWh_eJdIddPq"
      },
      "source": [
        "### import and implement model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gCRtcKOQddPs"
      },
      "outputs": [],
      "source": [
        "# packages\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.profiler\n",
        "from torch.nn import Conv2d, LeakyReLU, MaxPool2d, Linear # import them seperetly because I think its more readable\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from torchvision.transforms import Resize, ConvertImageDtype, Normalize, Compose\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "oed765-feAW5",
        "outputId": "e6f743dd-1768-4a0b-965c-290e4c34b04a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Nb3z1SiYddPt"
      },
      "outputs": [],
      "source": [
        "# set seed\n",
        "torch.manual_seed(126)\n",
        "\n",
        "# potential opti\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# cores set\n",
        "torch.set_num_threads(8)\n",
        "torch.set_num_interop_threads(8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9E8uVYlddPu"
      },
      "source": [
        "import data and load onto tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Q6dDll4iddPv"
      },
      "outputs": [],
      "source": [
        "class ImageDataset(torch.utils.data.Dataset): # Inherit from torch.utils.data.Dataset\n",
        "    def __init__(self, class_dir, img_dir): # Pass transforms in\n",
        "        self.img_labels = pd.read_csv(class_dir)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transforms.Compose([\n",
        "                transforms.Resize((224, 224), antialias=True),\n",
        "                transforms.ConvertImageDtype(torch.float32), # Convert to float\n",
        "            ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx): # Handle potential tensor index\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_filename = self.img_labels.iloc[idx, 0]\n",
        "        img_path = os.path.join(self.img_dir, img_filename)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "\n",
        "        image = read_image(img_path)\n",
        "        image = image.type(torch.float32) # convert to more efficent dtype\n",
        "\n",
        "        # Apply transforms\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Convert label to tensor (assuming classification)\n",
        "        label = torch.tensor(label, dtype=torch.int8)\n",
        "\n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "wGeVYpTvddPv"
      },
      "outputs": [],
      "source": [
        "# directories for classes and images\n",
        "class_dir = '/content/drive/MyDrive/colab/class_ids.csv'\n",
        "image_dir = '/content/drive/MyDrive/colab/resize_data'\n",
        "\n",
        "# load dataset using made class function\n",
        "data_set = ImageDataset(class_dir, image_dir) # create dataset\n",
        "\n",
        "# set train and test set\n",
        "train_size = int(.75 * len(data_set))\n",
        "test_size = int(.125 * len(data_set))\n",
        "val_size = len(data_set) - test_size - train_size\n",
        "\n",
        "# random split\n",
        "training, testing, val = random_split(data_set, [train_size, test_size, val_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "CJmobBO9ddPw"
      },
      "outputs": [],
      "source": [
        "batch_size = 150 # batch size, up from 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "AwrREV61ddPw"
      },
      "outputs": [],
      "source": [
        "# load the split data on the tensors | added the colleate fn bc of corrupted files\n",
        "train_loader = DataLoader(training, batch_size=batch_size, num_workers=8, pin_memory=True,  prefetch_factor=2, shuffle=True) # workers to preload and increase training speed\n",
        "test_loader = DataLoader(testing, batch_size=batch_size, num_workers=8, pin_memory=True,  prefetch_factor=4,shuffle=True)\n",
        "val_loader = DataLoader(val, batch_size=batch_size, num_workers=8,pin_memory=True, prefetch_factor=4,shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86poE9r0ddPx"
      },
      "source": [
        "model without transfer learning (will add just wanted to build one from stratch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "JE5Wj9pdddPy"
      },
      "outputs": [],
      "source": [
        "# I chose to use a CNN for the image classifcation.\n",
        "# CNNs preform much better then feed forward networks for image classification tasks and are still easy to implement\n",
        "\n",
        "class CNN (nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # 1 input layer, to 32 filters, stride of one pixel, 3x3 kernal, padding = (kernal - 1)/2\n",
        "\n",
        "        # 3 layers like this\n",
        "        self.conv1 = Conv2d(in_channels=1, out_channels=32, stride=1, kernel_size=3, padding=1)\n",
        "        self.Lrelu1 = LeakyReLU() # better preformance on average compared to regular ReLu\n",
        "        self.bn1 = nn.BatchNorm2d(32)# prevent exploding / vanishing gradients\n",
        "        self.conv2 = Conv2d(in_channels=32, out_channels=32, stride=1, kernel_size=5, padding=2)\n",
        "        self.Lrelu2 = LeakyReLU()\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.maxpool1 = MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        # 3 layers like this\n",
        "        self.conv3 = Conv2d(in_channels=32, out_channels=64, stride=1, kernel_size=5, padding=2)\n",
        "        self.Lrelu3 = LeakyReLU() # better preformance on average compared to regular ReLu\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.conv4 = Conv2d(in_channels=64, out_channels=64, stride=1, kernel_size=7, padding=3)\n",
        "        self.Lrelu4 = LeakyReLU()\n",
        "        self.bn4 = nn.BatchNorm2d(64)\n",
        "        self.maxpool2 = MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        # 3 layers like this\n",
        "        self.conv5 = Conv2d(in_channels=64, out_channels=128, stride=1, kernel_size=5, padding=2)\n",
        "        self.Lrelu5 = LeakyReLU() # better preformance on average compared to regular ReLu\n",
        "        self.bn5 = nn.BatchNorm2d(128)\n",
        "        self.conv6 = Conv2d(in_channels=128, out_channels=128, stride=1, kernel_size=3, padding=1)\n",
        "        self.Lrelu6 = LeakyReLU()\n",
        "        self.bn6 = nn.BatchNorm2d(128)\n",
        "        self.maxpool3 = MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        # reduce the number of features\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        # fully connected layers\n",
        "        self.fc1 = Linear(128, 512) # pool layer reduces\n",
        "        self.relu1 = LeakyReLU()\n",
        "        self.fc3 = Linear(512, 256)\n",
        "        self.relu3 = LeakyReLU()\n",
        "        self.dropout2 = nn.Dropout(p = 0.4)\n",
        "        self.fc4 = nn.Linear(256, 1) # one output\n",
        "\n",
        "\n",
        "        # this reduces overfitting making one neuron not resposnible for everything, also improves regualrization\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass through Convolutional Block 1\n",
        "        x = self.conv1(x)\n",
        "        x = self.Lrelu1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.Lrelu2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.maxpool1(x)\n",
        "\n",
        "        # Pass through Convolutional Block 2\n",
        "        x = self.conv3(x)\n",
        "        x = self.Lrelu3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.Lrelu4(x)\n",
        "        x = self.bn4(x)\n",
        "        x = self.maxpool2(x)\n",
        "\n",
        "        # Pass through Convolutional Block 3\n",
        "        x = self.conv5(x)\n",
        "        x = self.Lrelu5(x)\n",
        "        x = self.bn5(x)\n",
        "        x = self.conv6(x)\n",
        "        x = self.Lrelu6(x)\n",
        "        x = self.bn6(x)\n",
        "        x = self.maxpool3(x)\n",
        "\n",
        "        # pooling layer\n",
        "        x = self.global_avg_pool(x)\n",
        "\n",
        "        # flatten\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        # Pass through Fully Connected Layers\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.dropout2(x) # Apply dropout\n",
        "        x = self.relu3(x)\n",
        "\n",
        "        # Pass through the final Linear layer\n",
        "        x = self.fc4(x)\n",
        "\n",
        "        # Apply Dropout, sigmoind applied in loss function, better preformance\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgPXYlfeddPz"
      },
      "source": [
        "model training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "NsRxUn7KddP0",
        "outputId": "f46e216e-9c4b-42ca-be5b-bf47a8027788",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Available: True\n",
            "Number of CUDA devices: 1\n",
            "Device 0: NVIDIA L4\n"
          ]
        }
      ],
      "source": [
        "cuda_available = torch.cuda.is_available()\n",
        "print(f\"CUDA Available: {cuda_available}\")\n",
        "if cuda_available:\n",
        "    print(f\"Number of CUDA devices: {torch.cuda.device_count()}\")\n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")\n",
        "\n",
        "device = \"cuda\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "uPsC6mgtddP0",
        "outputId": "e46a689c-d213-4684-d650-455a090a68ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (Lrelu1): LeakyReLU(negative_slope=0.01)\n",
              "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (Lrelu2): LeakyReLU(negative_slope=0.01)\n",
              "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (Lrelu3): LeakyReLU(negative_slope=0.01)\n",
              "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv4): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
              "  (Lrelu4): LeakyReLU(negative_slope=0.01)\n",
              "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv5): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (Lrelu5): LeakyReLU(negative_slope=0.01)\n",
              "  (bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (Lrelu6): LeakyReLU(negative_slope=0.01)\n",
              "  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (global_avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
              "  (relu1): LeakyReLU(negative_slope=0.01)\n",
              "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (relu3): LeakyReLU(negative_slope=0.01)\n",
              "  (dropout2): Dropout(p=0.4, inplace=False)\n",
              "  (fc4): Linear(in_features=256, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# run model on GPU\n",
        "model = CNN()\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "bdS1X4L2ddP1"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.1 # standard learning rate\n",
        "loss_fn = nn.BCEWithLogitsLoss() # add activation function in here\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate) # adam w has better preformance, weight decay is applied sep,\n",
        "# leads to more peak ram may have to reduce batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "5AQ_d86HddP1"
      },
      "outputs": [],
      "source": [
        "def val_set_test():\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    n_rounds = 0\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        for batch_idx, (image, label) in enumerate(val_loader):\n",
        "            # set up\n",
        "            image = image.to(device).float()\n",
        "            label = label.to(device).float()\n",
        "\n",
        "            # make predictions on val\n",
        "            predictions = model(image)\n",
        "            predictions = predictions.squeeze()\n",
        "            loss = loss_fn(predictions, label)\n",
        "\n",
        "            # loss\n",
        "            val_loss += loss.item()\n",
        "            n_rounds = batch_idx + 1\n",
        "\n",
        "    model.train()  # Set model back to training mode\n",
        "    return val_loss / n_rounds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "klcOTFtzddP1"
      },
      "outputs": [],
      "source": [
        "def training(epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    training_losses = []  # To track loss history\n",
        "    min_loss = float('inf') # es min loss\n",
        "    patience = 0 # es track\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)# learning rate decay, 0.1 is default gammma\n",
        "    for i in range(epochs):\n",
        "        tloss = 0.0\n",
        "        n_rounds = 0\n",
        "        for batch_idx, (image, label) in enumerate(train_loader):\n",
        "            # Move data to device and ensure correct data types\n",
        "            image = image.to(device).float()\n",
        "            label = label.to(device).float()\n",
        "\n",
        "            # Zero gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            predictions = model(image)\n",
        "            predictions = predictions.squeeze()\n",
        "            loss = loss_fn(predictions, label)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Accumulate loss\n",
        "            tloss += loss.item()\n",
        "            n_rounds = batch_idx + 1\n",
        "            avg_loss = tloss / n_rounds\n",
        "\n",
        "            # Update training loss stats\n",
        "            training_losses.append(avg_loss)\n",
        "\n",
        "            # val process\n",
        "            print(f\"batch {batch_idx} is done\")\n",
        "\n",
        "        # early stopping\n",
        "        val_loss = val_set_test() # return loss for validation set\n",
        "\n",
        "        if val_loss > min_loss:\n",
        "            patience += 1\n",
        "\n",
        "        if val_loss < min_loss:\n",
        "            min_loss = val_loss\n",
        "            patience = 0\n",
        "\n",
        "        if patience > 10: # early stopping after 5 rounds\n",
        "            print(f\"early stopping at round {i}\")\n",
        "            return model, training_losses\n",
        "\n",
        "        scheduler.step() # step for learning rate decay\n",
        "        print(f\"{avg_loss} is the average loss at epoch {i}\") # still provide avg and epoch after through early stopping\n",
        "\n",
        "\n",
        "    return model, training_losses\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "to20MjqAddP1"
      },
      "source": [
        "#### fake testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiTJsBlfddP2",
        "outputId": "ef99f669-e1f7-4597-9b60-f5d3b0fce3bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating fake data...\n",
            "Fake data created in 0.43 seconds.\n",
            "Fake DataLoader created with workers=0, pin_memory=False\n"
          ]
        }
      ],
      "source": [
        "import time # For basic timing\n",
        "\n",
        "# --- Create Fake Data (adjust shape/size/type) ---\n",
        "print(\"Creating fake data...\")\n",
        "start_time = time.time()\n",
        "num_samples = 500\n",
        "batch_size = 64 # Your batch size\n",
        "input_shape = (1, 224, 224) # Example image shape\n",
        "num_classes = 2 # Example output classes\n",
        "# Use float() for typical model inputs, long() for typical classification labels\n",
        "fake_inputs = torch.randn(num_samples, *input_shape, dtype=torch.float32)\n",
        "fake_labels = torch.randint(0, num_classes, (num_samples,), dtype=torch.long)\n",
        "\n",
        "# Create fake class IDs DataFrame\n",
        "fake_df = pd.DataFrame({\n",
        "    'filename': [f'fake_image_{i}.jpg' for i in range(num_samples)],\n",
        "    'label': fake_labels.numpy()\n",
        "})\n",
        "\n",
        "# Create a temporary directory to store fake images\n",
        "fake_images = torch.randn(num_samples, *input_shape, dtype=torch.float32)\n",
        "label_array = fake_labels.float()  # Convert to float for binary classification\n",
        "\n",
        "# Create fake dataset directly without saving files\n",
        "class FakeDataset():\n",
        "    def __init__(self, images, labels):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transforms = Resize((224,224), antialias=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = self.transforms(image)\n",
        "        return image, label\n",
        "\n",
        "# Create dataset and dataloader\n",
        "fake_dataset = FakeDataset(fake_images, label_array)\n",
        "print(f\"Fake data created in {time.time() - start_time:.2f} seconds.\")\n",
        "\n",
        "# Create DataLoader with same parameters as training loader\n",
        "fake_loader = DataLoader(fake_dataset, batch_size=batch_size, shuffle=True,\n",
        "                        num_workers=0, prefetch_factor=None)\n",
        "print(f\"Fake DataLoader created with workers={fake_loader.num_workers}, pin_memory={fake_loader.pin_memory}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_A5NdTzddP2",
        "outputId": "afca5254-92ec-4c4f-ff4b-cf45c35043d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          training_loop         0.00%       0.000us         0.00%       0.000us       0.000us       6.518ms       111.38%       6.518ms       6.518ms             1  \n",
            "                                          training_loop        17.05%       1.370ms        75.72%       6.085ms       6.085ms       0.000us         0.00%       5.852ms       5.852ms             1  \n",
            "                                           aten::conv2d         0.66%      52.985us        30.70%       2.467ms     411.192us       0.000us         0.00%       5.200ms     866.739us             6  \n",
            "                                      aten::convolution         1.37%     110.252us        30.04%       2.414ms     402.362us       0.000us         0.00%       5.200ms     866.739us             6  \n",
            "                                     aten::_convolution         1.76%     141.434us        28.67%       2.304ms     383.986us       0.000us         0.00%       5.200ms     866.739us             6  \n",
            "                                aten::cudnn_convolution        14.09%       1.132ms        24.40%       1.961ms     326.851us       4.992ms        85.32%       4.992ms     832.073us             6  \n",
            "_5x_cudnn_volta_scudnn_128x32_sliced1x4_ldg4_relu_ex...         0.00%       0.000us         0.00%       0.000us       0.000us       2.694ms        46.05%       2.694ms       1.347ms             2  \n",
            "        _5x_cudnn_volta_scudnn_128x32_relu_medium_nn_v1         0.00%       0.000us         0.00%       0.000us       0.000us       1.298ms        22.18%       1.298ms     648.962us             2  \n",
            "_5x_cudnn_volta_scudnn_128x64_relu_xregs_large_nn_v1...         0.00%       0.000us         0.00%       0.000us       0.000us     586.387us        10.02%     586.387us     586.387us             1  \n",
            "                                       aten::batch_norm         0.28%      22.441us        10.00%     803.837us     133.973us       0.000us         0.00%     296.827us      49.471us             6  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 8.037ms\n",
            "Self CUDA time total: 5.852ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get a batch of data from test_loader\n",
        "# Get only 2 batches (small subset) from test_loader\n",
        "images, _ = next(iter(train_loader))\n",
        "images = images[:1].to(device).float()  # Take only 2 samples\n",
        "\n",
        "with torch.profiler.profile(\n",
        "    activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
        "    record_shapes=True,\n",
        "    ) as prof:\n",
        "        # Code to be profiled, e.g., model inference or training loop\n",
        "        with torch.profiler.record_function(\"training_loop\"):\n",
        "            output = model(images)\n",
        "\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ruxqm0UCddP2"
      },
      "source": [
        "#### training call and eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "A2D5SoSmddP2",
        "outputId": "17c15a75-ed4b-48d1-f166-7339cf073df7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch 0 is done\n",
            "batch 1 is done\n",
            "batch 2 is done\n",
            "batch 3 is done\n",
            "batch 4 is done\n",
            "batch 5 is done\n",
            "batch 6 is done\n",
            "batch 7 is done\n",
            "batch 8 is done\n",
            "batch 9 is done\n",
            "batch 10 is done\n",
            "batch 11 is done\n",
            "batch 12 is done\n",
            "batch 13 is done\n",
            "batch 14 is done\n",
            "batch 15 is done\n",
            "batch 16 is done\n",
            "batch 17 is done\n",
            "batch 18 is done\n",
            "batch 19 is done\n",
            "batch 20 is done\n",
            "batch 21 is done\n",
            "batch 22 is done\n",
            "batch 23 is done\n",
            "batch 24 is done\n",
            "batch 25 is done\n",
            "batch 26 is done\n",
            "batch 27 is done\n",
            "batch 28 is done\n",
            "batch 29 is done\n",
            "batch 30 is done\n",
            "batch 31 is done\n",
            "batch 32 is done\n",
            "batch 33 is done\n",
            "batch 34 is done\n",
            "batch 35 is done\n",
            "batch 36 is done\n",
            "batch 37 is done\n",
            "batch 38 is done\n",
            "batch 39 is done\n",
            "batch 40 is done\n",
            "batch 41 is done\n",
            "batch 42 is done\n",
            "batch 43 is done\n",
            "batch 44 is done\n",
            "batch 45 is done\n",
            "batch 46 is done\n",
            "batch 47 is done\n",
            "batch 48 is done\n",
            "batch 49 is done\n",
            "batch 50 is done\n",
            "batch 51 is done\n",
            "batch 52 is done\n",
            "batch 53 is done\n",
            "batch 54 is done\n",
            "batch 55 is done\n",
            "batch 56 is done\n",
            "batch 57 is done\n",
            "batch 58 is done\n",
            "batch 59 is done\n",
            "batch 60 is done\n",
            "batch 61 is done\n",
            "batch 62 is done\n",
            "batch 63 is done\n",
            "batch 64 is done\n",
            "batch 65 is done\n",
            "batch 66 is done\n",
            "batch 67 is done\n",
            "batch 68 is done\n",
            "batch 69 is done\n",
            "batch 70 is done\n",
            "batch 71 is done\n",
            "batch 72 is done\n",
            "batch 73 is done\n",
            "batch 74 is done\n",
            "batch 75 is done\n",
            "batch 76 is done\n",
            "batch 77 is done\n",
            "batch 78 is done\n",
            "batch 79 is done\n",
            "batch 80 is done\n",
            "batch 81 is done\n",
            "batch 82 is done\n",
            "batch 83 is done\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-896262f0904f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-e322a1e39c7c>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(epochs)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mn_rounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0;31m# Move data to device and ensure correct data types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1410\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "t_model, t_loss = training(300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXtQNyjcddP3"
      },
      "outputs": [],
      "source": [
        "results = [] # array for res\n",
        "model.eval() # set model to eval mode, disables dropout\n",
        "\n",
        "# testing loop\n",
        "for images, labels in test_loader:\n",
        "    images = images.to(device).float() # load onto device with correct data type\n",
        "    labels = labels.to(device).float()\n",
        "\n",
        "    predictions = model(images) # make predections on image in model\n",
        "    preds_1_0 = torch.where(predictions>0.5, 1, 0)\n",
        "    correct = (preds_1_0 == labels)\n",
        "    results.append(correct.detach().cpu().numpy().mean())\n",
        "\n",
        "    precision = BinaryPrecision().to(device) # binary percison\n",
        "    result = precision(preds_1_0.squeeze(), labels)\n",
        "\n",
        "\n",
        "accuracy = np.array(results).mean()\n",
        "print(accuracy)\n",
        "print(f\"Binary Precision: {result}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}