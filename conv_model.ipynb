{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWh_eJdIddPq"
      },
      "source": [
        "### import and implement model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gCRtcKOQddPs"
      },
      "outputs": [],
      "source": [
        "# packages\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.profiler\n",
        "from torch.nn import Conv2d, LeakyReLU, MaxPool2d, Linear # import them seperetly because I think its more readable\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch\n",
        "import cv2\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import gc\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO1WRLUyIEel"
      },
      "source": [
        "device settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Nb3z1SiYddPt"
      },
      "outputs": [],
      "source": [
        "# set seed\n",
        "torch.manual_seed(126)\n",
        "\n",
        "# potential opti\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# cores set\n",
        "torch.set_num_threads(8)\n",
        "torch.set_num_interop_threads(8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avamSIV5IEeo"
      },
      "source": [
        "local settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7zSIiJlvIEeo",
        "outputId": "47802de1-5642-4e90-adb2-7e4ce2b69656",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'C:/Users/dalto/OneDrive/Pictures/Documents/Projects/Fracture/'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-2500559cbea2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C:/Users/dalto/OneDrive/Pictures/Documents/Projects/Fracture/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclass_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./images/class_ids.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimage_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./images/resize_data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/dalto/OneDrive/Pictures/Documents/Projects/Fracture/'"
          ]
        }
      ],
      "source": [
        "os.chdir('C:/Users/dalto/OneDrive/Pictures/Documents/Projects/Fracture/')\n",
        "class_dir = './images/class_ids.csv'\n",
        "image_dir = './images/resize_data'\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UY5yl9wiIEeq"
      },
      "source": [
        "colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wGeVYpTvddPv",
        "outputId": "b961d14f-d167-49b9-819c-1124298604aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# directories for classes and images\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "class_dir = '/content/drive/MyDrive/colab/class_ids.csv'\n",
        "image_dir = '/content/drive/Othercomputers/My Laptop/resize_data'\n",
        "batch_size = 128 # batch size, up from 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RekxyVUIEes"
      },
      "source": [
        "image dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "XjAPeYh_IEet"
      },
      "outputs": [],
      "source": [
        "class ImageDataset(torch.utils.data.Dataset): # Inherit from torch.utils.data.Dataset\n",
        "    def __init__(self, class_dir, img_dir): # Pass transforms in\n",
        "        self.img_labels = pd.read_csv(class_dir)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transforms.Compose([\n",
        "                transforms.Resize((224, 224), antialias=True),\n",
        "                transforms.ConvertImageDtype(torch.float32), # Convert to float\n",
        "            ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx): # Handle potential tensor index\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_filename = self.img_labels.iloc[idx, 0]\n",
        "        img_path = os.path.join(self.img_dir, img_filename)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "\n",
        "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        image = np.expand_dims(image, axis=0)\n",
        "        image = torch.from_numpy(image).float().div(255.0)\n",
        "\n",
        "        # Apply transforms\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Convert label to tensor (assuming classification)\n",
        "        label = torch.tensor(label, dtype=torch.int8)\n",
        "\n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "39KNd9FpIEet"
      },
      "outputs": [],
      "source": [
        "# load dataset using made class function\n",
        "data_set = ImageDataset(class_dir, image_dir) # create dataset\n",
        "\n",
        "# set train and test set\n",
        "train_size = int(.75 * len(data_set))\n",
        "test_size = int(.05 * len(data_set))\n",
        "val_size = len(data_set) - test_size - train_size\n",
        "\n",
        "# random split\n",
        "training, testing, val = random_split(data_set, [train_size, test_size, val_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "AwrREV61ddPw"
      },
      "outputs": [],
      "source": [
        "# load the split data on the tensors | added the colleate fn bc of corrupted files\n",
        "train_loader = DataLoader(training, batch_size=batch_size, num_workers=8, pin_memory=True,  prefetch_factor=4, shuffle=True) # workers to preload and increase training speed\n",
        "test_loader = DataLoader(testing, batch_size=batch_size, num_workers=8, pin_memory=True,  prefetch_factor=4,shuffle=True)\n",
        "val_loader = DataLoader(val, batch_size=batch_size, num_workers=8,pin_memory=True, prefetch_factor=4,shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86poE9r0ddPx"
      },
      "source": [
        "model without transfer learning (will add just wanted to build one from stratch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JE5Wj9pdddPy"
      },
      "outputs": [],
      "source": [
        "# I chose to use a CNN for the image classifcation.\n",
        "# CNNs preform much better then feed forward networks for image classification tasks and are still easy to implement\n",
        "\n",
        "class CNN (nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # 1 input layer, to 32 filters, stride of one pixel, 3x3 kernal, padding = (kernal - 1)/2\n",
        "\n",
        "        # 3 layers like this\n",
        "        self.conv1 = Conv2d(in_channels=1, out_channels=64, stride=1, kernel_size=3, padding=1)\n",
        "        self.Lrelu1 = LeakyReLU() # better preformance on average compared to regular ReLu\n",
        "        self.bn1 = nn.BatchNorm2d(64)# prevent exploding / vanishing gradients\n",
        "        self.conv2 = Conv2d(in_channels=64, out_channels=64, stride=1, kernel_size=5, padding=2)\n",
        "        self.Lrelu2 = LeakyReLU()\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.maxpool1 = MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        # 3 layers like this\n",
        "        self.conv3 = Conv2d(in_channels=64, out_channels=128, stride=1, kernel_size=5, padding=2)\n",
        "        self.Lrelu3 = LeakyReLU() # better preformance on average compared to regular ReLu\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = Conv2d(in_channels=128, out_channels=128, stride=1, kernel_size=7, padding=3)\n",
        "        self.Lrelu4 = LeakyReLU()\n",
        "        self.bn4 = nn.BatchNorm2d(128)\n",
        "        self.maxpool2 = MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        # 3 layers like this\n",
        "        self.conv5 = Conv2d(in_channels=128, out_channels=256, stride=1, kernel_size=5, padding=2)\n",
        "        self.Lrelu5 = LeakyReLU() # better preformance on average compared to regular ReLu\n",
        "        self.bn5 = nn.BatchNorm2d(256)\n",
        "        self.conv6 = Conv2d(in_channels=256, out_channels=256, stride=1, kernel_size=3, padding=1)\n",
        "        self.Lrelu6 = LeakyReLU()\n",
        "        self.bn6 = nn.BatchNorm2d(256)\n",
        "        self.maxpool3 = MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        # reduce the number of features\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        # fully connected layers\n",
        "        self.fc1 = Linear(256, 512) # pool layer reduces\n",
        "        self.relu1 = LeakyReLU()\n",
        "        self.fc3 = Linear(512, 256)\n",
        "        self.relu3 = LeakyReLU()\n",
        "        self.dropout2 = nn.Dropout(p = 0.4)\n",
        "        self.fc4 = nn.Linear(256, 1) # one output\n",
        "\n",
        "\n",
        "        # this reduces overfitting making one neuron not resposnible for everything, also improves regualrization\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass through Convolutional Block 1\n",
        "        x = self.conv1(x)\n",
        "        x = self.Lrelu1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.Lrelu2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.maxpool1(x)\n",
        "\n",
        "        # Pass through Convolutional Block 2\n",
        "        x = self.conv3(x)\n",
        "        x = self.Lrelu3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.Lrelu4(x)\n",
        "        x = self.bn4(x)\n",
        "        x = self.maxpool2(x)\n",
        "\n",
        "        # Pass through Convolutional Block 3\n",
        "        x = self.conv5(x)\n",
        "        x = self.Lrelu5(x)\n",
        "        x = self.bn5(x)\n",
        "        x = self.conv6(x)\n",
        "        x = self.Lrelu6(x)\n",
        "        x = self.bn6(x)\n",
        "        x = self.maxpool3(x)\n",
        "\n",
        "        # pooling layer\n",
        "        x = self.global_avg_pool(x)\n",
        "\n",
        "        # flatten\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        # Pass through Fully Connected Layers\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.dropout2(x) # Apply dropout\n",
        "        x = self.relu3(x)\n",
        "\n",
        "        # Pass through the final Linear layer\n",
        "        x = self.fc4(x)\n",
        "\n",
        "        # Apply Dropout, sigmoind applied in loss function, better preformance\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgPXYlfeddPz"
      },
      "source": [
        "model training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsRxUn7KddP0",
        "outputId": "7ba44378-ea0e-46ba-f409-34887f4f91c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Available: True\n",
            "Number of CUDA devices: 1\n",
            "Device 0: NVIDIA L4\n"
          ]
        }
      ],
      "source": [
        "cuda_available = torch.cuda.is_available()\n",
        "print(f\"CUDA Available: {cuda_available}\")\n",
        "if cuda_available:\n",
        "    print(f\"Number of CUDA devices: {torch.cuda.device_count()}\")\n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")\n",
        "\n",
        "device = \"cuda\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPsC6mgtddP0",
        "outputId": "7666cd34-21d9-444e-aa4b-10a9859dc948"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (Lrelu1): LeakyReLU(negative_slope=0.01)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (Lrelu2): LeakyReLU(negative_slope=0.01)\n",
              "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (Lrelu3): LeakyReLU(negative_slope=0.01)\n",
              "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv4): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
              "  (Lrelu4): LeakyReLU(negative_slope=0.01)\n",
              "  (bn4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv5): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (Lrelu5): LeakyReLU(negative_slope=0.01)\n",
              "  (bn5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (Lrelu6): LeakyReLU(negative_slope=0.01)\n",
              "  (bn6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (global_avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
              "  (relu1): LeakyReLU(negative_slope=0.01)\n",
              "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (relu3): LeakyReLU(negative_slope=0.01)\n",
              "  (dropout2): Dropout(p=0.4, inplace=False)\n",
              "  (fc4): Linear(in_features=256, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# run model on GPU\n",
        "model = CNN()\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bdS1X4L2ddP1"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001 # standard learning rate\n",
        "loss_fn = nn.BCEWithLogitsLoss() # add activation function in here\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate) # adam w has better preformance, weight decay is applied sep,\n",
        "# leads to more peak ram may have to reduce batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5AQ_d86HddP1"
      },
      "outputs": [],
      "source": [
        "def val_set_test():\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    n_rounds = 0\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        for batch_idx, (image, label) in enumerate(val_loader):\n",
        "            # set up\n",
        "            image = image.to(device).float()\n",
        "            label = label.to(device).float()\n",
        "\n",
        "            # make predictions on val\n",
        "            predictions = model(image)\n",
        "            predictions = predictions.squeeze()\n",
        "            loss = loss_fn(predictions, label)\n",
        "\n",
        "            # loss\n",
        "            val_loss += loss.item()\n",
        "            n_rounds = batch_idx + 1\n",
        "\n",
        "    model.train()  # Set model back to training mode\n",
        "    return val_loss / n_rounds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "tQIx6ms72Ot0"
      },
      "outputs": [],
      "source": [
        "milestones = [5, 18] # change the lr at 4, 12 , 28 | from experiment\n",
        "gamma = 0.1 # Multiply LR by 0.1 at each milestone\n",
        "scheduler = MultiStepLR(optimizer, milestones=milestones, gamma=gamma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "klcOTFtzddP1"
      },
      "outputs": [],
      "source": [
        "def training(epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    training_losses = []  # To track loss history\n",
        "    min_loss = float('inf') # es min loss\n",
        "    patience = 0 # es track\n",
        "    for i in range(epochs):\n",
        "        tloss = 0.0\n",
        "        n_rounds = 0\n",
        "        for batch_idx, (image, label) in enumerate(train_loader):\n",
        "            # Move data to device and ensure correct data types\n",
        "            image = image.to(device).float()\n",
        "            label = label.to(device).float()\n",
        "\n",
        "            # Zero gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            predictions = model(image)\n",
        "            predictions = predictions.squeeze()\n",
        "            loss = loss_fn(predictions, label)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Accumulate loss\n",
        "            tloss += loss.item()\n",
        "            n_rounds = batch_idx + 1\n",
        "            avg_loss = tloss / n_rounds\n",
        "\n",
        "            # Update training loss stats\n",
        "            training_losses.append(avg_loss)\n",
        "\n",
        "             # early stopping\n",
        "            val_loss = val_set_test() # return loss for validation set\n",
        "\n",
        "            if val_loss > min_loss:\n",
        "              patience += 1\n",
        "\n",
        "            if val_loss < min_loss:\n",
        "              min_loss = val_loss\n",
        "              patience = 0\n",
        "\n",
        "            if patience > 20: # early stopping after 5 rounds\n",
        "              print(f\"early stopping at round {i}\")\n",
        "              return model, training_losses\n",
        "\n",
        "\n",
        "            # val process\n",
        "            print(f\"batch {batch_idx} is done\")\n",
        "\n",
        "\n",
        "        scheduler.step() # step for learning rate decay\n",
        "        print(f\"{avg_loss} is the average loss at epoch {i}\") # still provide avg and epoch after through early stopping\n",
        "\n",
        "\n",
        "    return model, training_losses\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "to20MjqAddP1"
      },
      "source": [
        "#### fake testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiTJsBlfddP2",
        "outputId": "ef99f669-e1f7-4597-9b60-f5d3b0fce3bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating fake data...\n",
            "Fake data created in 0.43 seconds.\n",
            "Fake DataLoader created with workers=0, pin_memory=False\n"
          ]
        }
      ],
      "source": [
        "import time # For basic timing\n",
        "\n",
        "# --- Create Fake Data (adjust shape/size/type) ---\n",
        "print(\"Creating fake data...\")\n",
        "start_time = time.time()\n",
        "num_samples = 500\n",
        "batch_size = 64 # Your batch size\n",
        "input_shape = (1, 224, 224) # Example image shape\n",
        "num_classes = 2 # Example output classes\n",
        "# Use float() for typical model inputs, long() for typical classification labels\n",
        "fake_inputs = torch.randn(num_samples, *input_shape, dtype=torch.float32)\n",
        "fake_labels = torch.randint(0, num_classes, (num_samples,), dtype=torch.long)\n",
        "\n",
        "# Create fake class IDs DataFrame\n",
        "fake_df = pd.DataFrame({\n",
        "    'filename': [f'fake_image_{i}.jpg' for i in range(num_samples)],\n",
        "    'label': fake_labels.numpy()\n",
        "})\n",
        "\n",
        "# Create a temporary directory to store fake images\n",
        "fake_images = torch.randn(num_samples, *input_shape, dtype=torch.float32)\n",
        "label_array = fake_labels.float()  # Convert to float for binary classification\n",
        "\n",
        "# Create fake dataset directly without saving files\n",
        "class FakeDataset():\n",
        "    def __init__(self, images, labels):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transforms = Resize((224,224), antialias=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = self.transforms(image)\n",
        "        return image, label\n",
        "\n",
        "# Create dataset and dataloader\n",
        "fake_dataset = FakeDataset(fake_images, label_array)\n",
        "print(f\"Fake data created in {time.time() - start_time:.2f} seconds.\")\n",
        "\n",
        "# Create DataLoader with same parameters as training loader\n",
        "fake_loader = DataLoader(fake_dataset, batch_size=batch_size, shuffle=True,\n",
        "                        num_workers=0, prefetch_factor=None)\n",
        "print(f\"Fake DataLoader created with workers={fake_loader.num_workers}, pin_memory={fake_loader.pin_memory}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_A5NdTzddP2",
        "outputId": "afca5254-92ec-4c4f-ff4b-cf45c35043d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          training_loop         0.00%       0.000us         0.00%       0.000us       0.000us       6.518ms       111.38%       6.518ms       6.518ms             1  \n",
            "                                          training_loop        17.05%       1.370ms        75.72%       6.085ms       6.085ms       0.000us         0.00%       5.852ms       5.852ms             1  \n",
            "                                           aten::conv2d         0.66%      52.985us        30.70%       2.467ms     411.192us       0.000us         0.00%       5.200ms     866.739us             6  \n",
            "                                      aten::convolution         1.37%     110.252us        30.04%       2.414ms     402.362us       0.000us         0.00%       5.200ms     866.739us             6  \n",
            "                                     aten::_convolution         1.76%     141.434us        28.67%       2.304ms     383.986us       0.000us         0.00%       5.200ms     866.739us             6  \n",
            "                                aten::cudnn_convolution        14.09%       1.132ms        24.40%       1.961ms     326.851us       4.992ms        85.32%       4.992ms     832.073us             6  \n",
            "_5x_cudnn_volta_scudnn_128x32_sliced1x4_ldg4_relu_ex...         0.00%       0.000us         0.00%       0.000us       0.000us       2.694ms        46.05%       2.694ms       1.347ms             2  \n",
            "        _5x_cudnn_volta_scudnn_128x32_relu_medium_nn_v1         0.00%       0.000us         0.00%       0.000us       0.000us       1.298ms        22.18%       1.298ms     648.962us             2  \n",
            "_5x_cudnn_volta_scudnn_128x64_relu_xregs_large_nn_v1...         0.00%       0.000us         0.00%       0.000us       0.000us     586.387us        10.02%     586.387us     586.387us             1  \n",
            "                                       aten::batch_norm         0.28%      22.441us        10.00%     803.837us     133.973us       0.000us         0.00%     296.827us      49.471us             6  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 8.037ms\n",
            "Self CUDA time total: 5.852ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get a batch of data from test_loader\n",
        "# Get only 2 batches (small subset) from test_loader\n",
        "images, _ = next(iter(train_loader))\n",
        "images = images[:1].to(device).float()  # Take only 2 samples\n",
        "\n",
        "with torch.profiler.profile(\n",
        "    activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
        "    record_shapes=True,\n",
        "    ) as prof:\n",
        "        # Code to be profiled, e.g., model inference or training loop\n",
        "        with torch.profiler.record_function(\"training_loop\"):\n",
        "            output = model(images)\n",
        "\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ruxqm0UCddP2"
      },
      "source": [
        "#### training call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "p86cBUzl62TL"
      },
      "outputs": [],
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2D5SoSmddP2",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "t_model, t_loss = training(100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwSWciCD5oXW"
      },
      "source": [
        "#### Model Save"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = '/content/drive/MyDrive/colab/'\n",
        "PATH = os.path.join(save_dir, 'my_model_epoch_1.pth')\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "UZL-wUBgeDFw"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqaZCK-BIEe1"
      },
      "source": [
        "#### Model Eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Hf_BrHJmIEe2",
        "outputId": "553f67e5-e347-4901-e07c-66256ebefe61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (Lrelu1): LeakyReLU(negative_slope=0.01)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (Lrelu2): LeakyReLU(negative_slope=0.01)\n",
              "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (Lrelu3): LeakyReLU(negative_slope=0.01)\n",
              "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv4): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
              "  (Lrelu4): LeakyReLU(negative_slope=0.01)\n",
              "  (bn4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv5): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (Lrelu5): LeakyReLU(negative_slope=0.01)\n",
              "  (bn5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (Lrelu6): LeakyReLU(negative_slope=0.01)\n",
              "  (bn6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (global_avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
              "  (relu1): LeakyReLU(negative_slope=0.01)\n",
              "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (relu3): LeakyReLU(negative_slope=0.01)\n",
              "  (dropout2): Dropout(p=0.4, inplace=False)\n",
              "  (fc4): Linear(in_features=256, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('/content/drive/MyDrive/colab/my_model_epoch_1.pth'))\n",
        "model.eval() # Set the model to evaluation mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_7nPrU5VIEe3"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_loader, device, criterion=None):\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    running_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            if criterion:\n",
        "                loss = criterion(outputs, labels)\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Accuracy on the test set: {accuracy:.2f} %')\n",
        "\n",
        "    if criterion:\n",
        "        average_loss = running_loss / total\n",
        "        print(f'Average loss on the test set: {average_loss:.4f}')\n",
        "        return accuracy, average_loss\n",
        "    else:\n",
        "        return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJqOnGK-IEe4"
      },
      "outputs": [],
      "source": [
        "evaluate_model(model, test_loader, device)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}