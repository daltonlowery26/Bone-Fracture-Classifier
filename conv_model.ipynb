{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWh_eJdIddPq"
      },
      "source": [
        "### import and implement model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "gCRtcKOQddPs"
      },
      "outputs": [],
      "source": [
        "# packages\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.profiler\n",
        "from torch.nn import Conv2d, LeakyReLU, MaxPool2d, Linear # import them seperetly because I think its more readable\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from torchvision.transforms import Resize, ConvertImageDtype, Normalize, Compose\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "oed765-feAW5",
        "outputId": "14b6e282-0f0b-46fc-c99d-1c7ed100bb58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Nb3z1SiYddPt",
        "outputId": "9c759773-87d5-4711-a914-3b96309adf4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error: cannot set number of interop threads after parallel work has started or set_num_interop_threads called",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-af4e9267e53a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# cores set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_num_threads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_num_interop_threads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Error: cannot set number of interop threads after parallel work has started or set_num_interop_threads called"
          ]
        }
      ],
      "source": [
        "# set seed\n",
        "torch.manual_seed(126)\n",
        "\n",
        "# potential opti\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# cores set\n",
        "torch.set_num_threads(8)\n",
        "torch.set_num_interop_threads(8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9E8uVYlddPu"
      },
      "source": [
        "import data and load onto tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Q6dDll4iddPv"
      },
      "outputs": [],
      "source": [
        "class ImageDataset(torch.utils.data.Dataset): # Inherit from torch.utils.data.Dataset\n",
        "    def __init__(self, class_dir, img_dir): # Pass transforms in\n",
        "        self.img_labels = pd.read_csv(class_dir)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transforms.Compose([\n",
        "                transforms.Resize((224, 224), antialias=True),\n",
        "                transforms.ConvertImageDtype(torch.float32), # Convert to float\n",
        "            ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx): # Handle potential tensor index\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_filename = self.img_labels.iloc[idx, 0]\n",
        "        img_path = os.path.join(self.img_dir, img_filename)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "\n",
        "        image = read_image(img_path)\n",
        "        image = image.type(torch.float32) # convert to more efficent dtype\n",
        "\n",
        "        # Apply transforms\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Convert label to tensor (assuming classification)\n",
        "        label = torch.tensor(label, dtype=torch.int8)\n",
        "\n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "wGeVYpTvddPv"
      },
      "outputs": [],
      "source": [
        "# directories for classes and images\n",
        "class_dir = '/content/drive/MyDrive/colab/class_ids.csv'\n",
        "image_dir = '/content/drive/MyDrive/colab/resize_data'\n",
        "\n",
        "# load dataset using made class function\n",
        "data_set = ImageDataset(class_dir, image_dir) # create dataset\n",
        "\n",
        "# set train and test set\n",
        "train_size = int(.75 * len(data_set))\n",
        "test_size = int(.125 * len(data_set))\n",
        "val_size = len(data_set) - test_size - train_size\n",
        "\n",
        "# random split\n",
        "training, testing, val = random_split(data_set, [train_size, test_size, val_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "CJmobBO9ddPw"
      },
      "outputs": [],
      "source": [
        "batch_size = 128 # batch size, up from 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "AwrREV61ddPw"
      },
      "outputs": [],
      "source": [
        "# load the split data on the tensors | added the colleate fn bc of corrupted files\n",
        "train_loader = DataLoader(training, batch_size=batch_size, num_workers=0, pin_memory=True,  prefetch_factor=None, shuffle=True) # workers to preload and increase training speed\n",
        "test_loader = DataLoader(testing, batch_size=batch_size, num_workers=8, pin_memory=True,  prefetch_factor=2,shuffle=True)\n",
        "val_loader = DataLoader(val, batch_size=batch_size, num_workers=8,pin_memory=True, prefetch_factor=2,shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86poE9r0ddPx"
      },
      "source": [
        "model without transfer learning (will add just wanted to build one from stratch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "JE5Wj9pdddPy"
      },
      "outputs": [],
      "source": [
        "# I chose to use a CNN for the image classifcation.\n",
        "# CNNs preform much better then feed forward networks for image classification tasks and are still easy to implement\n",
        "\n",
        "class CNN (nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # 1 input layer, to 32 filters, stride of one pixel, 3x3 kernal, padding = (kernal - 1)/2\n",
        "\n",
        "        # 3 layers like this\n",
        "        self.conv1 = Conv2d(in_channels=1, out_channels=32, stride=1, kernel_size=3, padding=1)\n",
        "        self.Lrelu1 = LeakyReLU() # better preformance on average compared to regular ReLu\n",
        "        self.bn1 = nn.BatchNorm2d(32)# prevent exploding / vanishing gradients\n",
        "        self.conv2 = Conv2d(in_channels=32, out_channels=32, stride=1, kernel_size=5, padding=2)\n",
        "        self.Lrelu2 = LeakyReLU()\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.maxpool1 = MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        # 3 layers like this\n",
        "        self.conv3 = Conv2d(in_channels=32, out_channels=64, stride=1, kernel_size=5, padding=2)\n",
        "        self.Lrelu3 = LeakyReLU() # better preformance on average compared to regular ReLu\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.conv4 = Conv2d(in_channels=64, out_channels=64, stride=1, kernel_size=7, padding=3)\n",
        "        self.Lrelu4 = LeakyReLU()\n",
        "        self.bn4 = nn.BatchNorm2d(64)\n",
        "        self.maxpool2 = MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        # 3 layers like this\n",
        "        self.conv5 = Conv2d(in_channels=64, out_channels=128, stride=1, kernel_size=5, padding=2)\n",
        "        self.Lrelu5 = LeakyReLU() # better preformance on average compared to regular ReLu\n",
        "        self.bn5 = nn.BatchNorm2d(128)\n",
        "        self.conv6 = Conv2d(in_channels=128, out_channels=128, stride=1, kernel_size=3, padding=1)\n",
        "        self.Lrelu6 = LeakyReLU()\n",
        "        self.bn6 = nn.BatchNorm2d(128)\n",
        "        self.maxpool3 = MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        # reduce the number of features\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        # fully connected layers\n",
        "        self.fc1 = Linear(128, 512) # pool layer reduces\n",
        "        self.relu1 = LeakyReLU()\n",
        "        self.fc3 = Linear(512, 256)\n",
        "        self.relu3 = LeakyReLU()\n",
        "        self.dropout2 = nn.Dropout(p = 0.4)\n",
        "        self.fc4 = nn.Linear(256, 1) # one output\n",
        "\n",
        "\n",
        "        # this reduces overfitting making one neuron not resposnible for everything, also improves regualrization\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass through Convolutional Block 1\n",
        "        x = self.conv1(x)\n",
        "        x = self.Lrelu1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.Lrelu2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.maxpool1(x)\n",
        "\n",
        "        # Pass through Convolutional Block 2\n",
        "        x = self.conv3(x)\n",
        "        x = self.Lrelu3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.Lrelu4(x)\n",
        "        x = self.bn4(x)\n",
        "        x = self.maxpool2(x)\n",
        "\n",
        "        # Pass through Convolutional Block 3\n",
        "        x = self.conv5(x)\n",
        "        x = self.Lrelu5(x)\n",
        "        x = self.bn5(x)\n",
        "        x = self.conv6(x)\n",
        "        x = self.Lrelu6(x)\n",
        "        x = self.bn6(x)\n",
        "        x = self.maxpool3(x)\n",
        "\n",
        "        # pooling layer\n",
        "        x = self.global_avg_pool(x)\n",
        "\n",
        "        # flatten\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        # Pass through Fully Connected Layers\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.dropout2(x) # Apply dropout\n",
        "        x = self.relu3(x)\n",
        "\n",
        "        # Pass through the final Linear layer\n",
        "        x = self.fc4(x)\n",
        "\n",
        "        # Apply Dropout, sigmoind applied in loss function, better preformance\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgPXYlfeddPz"
      },
      "source": [
        "model training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "NsRxUn7KddP0",
        "outputId": "7ed2911e-79ec-4a60-fa3c-6b1b7bacd6b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Available: True\n",
            "Number of CUDA devices: 1\n",
            "Device 0: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "cuda_available = torch.cuda.is_available()\n",
        "print(f\"CUDA Available: {cuda_available}\")\n",
        "if cuda_available:\n",
        "    print(f\"Number of CUDA devices: {torch.cuda.device_count()}\")\n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")\n",
        "\n",
        "device = \"cuda\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "uPsC6mgtddP0",
        "outputId": "586baec6-6a11-491d-b981-585c990cfad0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (Lrelu1): LeakyReLU(negative_slope=0.01)\n",
              "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (Lrelu2): LeakyReLU(negative_slope=0.01)\n",
              "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (Lrelu3): LeakyReLU(negative_slope=0.01)\n",
              "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv4): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
              "  (Lrelu4): LeakyReLU(negative_slope=0.01)\n",
              "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv5): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (Lrelu5): LeakyReLU(negative_slope=0.01)\n",
              "  (bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (Lrelu6): LeakyReLU(negative_slope=0.01)\n",
              "  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (global_avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
              "  (relu1): LeakyReLU(negative_slope=0.01)\n",
              "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (relu3): LeakyReLU(negative_slope=0.01)\n",
              "  (dropout2): Dropout(p=0.4, inplace=False)\n",
              "  (fc4): Linear(in_features=256, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "# run model on GPU\n",
        "model = CNN()\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "bdS1X4L2ddP1"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.1 # standard learning rate\n",
        "loss_fn = nn.BCEWithLogitsLoss() # add activation function in here\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate) # adam w has better preformance, weight decay is applied sep,\n",
        "# leads to more peak ram may have to reduce batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "5AQ_d86HddP1"
      },
      "outputs": [],
      "source": [
        "def val_set_test():\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    n_rounds = 0\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        for batch_idx, (image, label) in enumerate(val_loader):\n",
        "            # set up\n",
        "            image = image.to(device).float()\n",
        "            label = label.to(device).float()\n",
        "\n",
        "            # make predictions on val\n",
        "            predictions = model(image)\n",
        "            predictions = predictions.squeeze()\n",
        "            loss = loss_fn(predictions, label)\n",
        "\n",
        "            # loss\n",
        "            val_loss += loss.item()\n",
        "            n_rounds = batch_idx + 1\n",
        "\n",
        "    model.train()  # Set model back to training mode\n",
        "    return val_loss / n_rounds\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "klcOTFtzddP1"
      },
      "outputs": [],
      "source": [
        "def training(epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    training_losses = []  # To track loss history\n",
        "    min_loss = float('inf') # es min loss\n",
        "    patience = 0 # es track\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)# learning rate decay, 0.1 is default gammma\n",
        "    for i in range(epochs):\n",
        "        tloss = 0.0\n",
        "        n_rounds = 0\n",
        "        for batch_idx, (image, label) in enumerate(train_loader):\n",
        "            # Move data to device and ensure correct data types\n",
        "            image = image.to(device).float()\n",
        "            label = label.to(device).float()\n",
        "\n",
        "            # Zero gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            predictions = model(image)\n",
        "            predictions = predictions.squeeze()\n",
        "            loss = loss_fn(predictions, label)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Accumulate loss\n",
        "            tloss += loss.item()\n",
        "            n_rounds = batch_idx + 1\n",
        "            avg_loss = tloss / n_rounds\n",
        "\n",
        "            # Update training loss stats\n",
        "            training_losses.append(avg_loss)\n",
        "\n",
        "        # early stopping\n",
        "        val_loss = val_set_test() # return loss for validation set\n",
        "\n",
        "        if val_loss > min_loss:\n",
        "            patience += 1\n",
        "\n",
        "        if val_loss < min_loss:\n",
        "            min_loss = val_loss\n",
        "            patience = 0\n",
        "\n",
        "        if patience > 10: # early stopping after 5 rounds\n",
        "            print(f\"early stopping at round {i}\")\n",
        "            return model, training_losses\n",
        "\n",
        "        scheduler.step() # step for learning rate decay\n",
        "        print(f\"{avg_loss} is the average loss at epoch {i}\") # still provide avg and epoch after through early stopping\n",
        "\n",
        "\n",
        "    return model, training_losses\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "to20MjqAddP1"
      },
      "source": [
        "#### fake testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "RiTJsBlfddP2",
        "outputId": "ef99f669-e1f7-4597-9b60-f5d3b0fce3bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating fake data...\n",
            "Fake data created in 0.43 seconds.\n",
            "Fake DataLoader created with workers=0, pin_memory=False\n"
          ]
        }
      ],
      "source": [
        "import time # For basic timing\n",
        "\n",
        "# --- Create Fake Data (adjust shape/size/type) ---\n",
        "print(\"Creating fake data...\")\n",
        "start_time = time.time()\n",
        "num_samples = 500\n",
        "batch_size = 64 # Your batch size\n",
        "input_shape = (1, 224, 224) # Example image shape\n",
        "num_classes = 2 # Example output classes\n",
        "# Use float() for typical model inputs, long() for typical classification labels\n",
        "fake_inputs = torch.randn(num_samples, *input_shape, dtype=torch.float32)\n",
        "fake_labels = torch.randint(0, num_classes, (num_samples,), dtype=torch.long)\n",
        "\n",
        "# Create fake class IDs DataFrame\n",
        "fake_df = pd.DataFrame({\n",
        "    'filename': [f'fake_image_{i}.jpg' for i in range(num_samples)],\n",
        "    'label': fake_labels.numpy()\n",
        "})\n",
        "\n",
        "# Create a temporary directory to store fake images\n",
        "fake_images = torch.randn(num_samples, *input_shape, dtype=torch.float32)\n",
        "label_array = fake_labels.float()  # Convert to float for binary classification\n",
        "\n",
        "# Create fake dataset directly without saving files\n",
        "class FakeDataset():\n",
        "    def __init__(self, images, labels):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transforms = Resize((224,224), antialias=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = self.transforms(image)\n",
        "        return image, label\n",
        "\n",
        "# Create dataset and dataloader\n",
        "fake_dataset = FakeDataset(fake_images, label_array)\n",
        "print(f\"Fake data created in {time.time() - start_time:.2f} seconds.\")\n",
        "\n",
        "# Create DataLoader with same parameters as training loader\n",
        "fake_loader = DataLoader(fake_dataset, batch_size=batch_size, shuffle=True,\n",
        "                        num_workers=0, prefetch_factor=None)\n",
        "print(f\"Fake DataLoader created with workers={fake_loader.num_workers}, pin_memory={fake_loader.pin_memory}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "f_A5NdTzddP2",
        "outputId": "afca5254-92ec-4c4f-ff4b-cf45c35043d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          training_loop         0.00%       0.000us         0.00%       0.000us       0.000us       6.518ms       111.38%       6.518ms       6.518ms             1  \n",
            "                                          training_loop        17.05%       1.370ms        75.72%       6.085ms       6.085ms       0.000us         0.00%       5.852ms       5.852ms             1  \n",
            "                                           aten::conv2d         0.66%      52.985us        30.70%       2.467ms     411.192us       0.000us         0.00%       5.200ms     866.739us             6  \n",
            "                                      aten::convolution         1.37%     110.252us        30.04%       2.414ms     402.362us       0.000us         0.00%       5.200ms     866.739us             6  \n",
            "                                     aten::_convolution         1.76%     141.434us        28.67%       2.304ms     383.986us       0.000us         0.00%       5.200ms     866.739us             6  \n",
            "                                aten::cudnn_convolution        14.09%       1.132ms        24.40%       1.961ms     326.851us       4.992ms        85.32%       4.992ms     832.073us             6  \n",
            "_5x_cudnn_volta_scudnn_128x32_sliced1x4_ldg4_relu_ex...         0.00%       0.000us         0.00%       0.000us       0.000us       2.694ms        46.05%       2.694ms       1.347ms             2  \n",
            "        _5x_cudnn_volta_scudnn_128x32_relu_medium_nn_v1         0.00%       0.000us         0.00%       0.000us       0.000us       1.298ms        22.18%       1.298ms     648.962us             2  \n",
            "_5x_cudnn_volta_scudnn_128x64_relu_xregs_large_nn_v1...         0.00%       0.000us         0.00%       0.000us       0.000us     586.387us        10.02%     586.387us     586.387us             1  \n",
            "                                       aten::batch_norm         0.28%      22.441us        10.00%     803.837us     133.973us       0.000us         0.00%     296.827us      49.471us             6  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 8.037ms\n",
            "Self CUDA time total: 5.852ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get a batch of data from test_loader\n",
        "# Get only 2 batches (small subset) from test_loader\n",
        "images, _ = next(iter(train_loader))\n",
        "images = images[:1].to(device).float()  # Take only 2 samples\n",
        "\n",
        "with torch.profiler.profile(\n",
        "    activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
        "    record_shapes=True,\n",
        "    ) as prof:\n",
        "        # Code to be profiled, e.g., model inference or training loop\n",
        "        with torch.profiler.record_function(\"training_loop\"):\n",
        "            output = model(images)\n",
        "\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ruxqm0UCddP2"
      },
      "source": [
        "#### training call and eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2D5SoSmddP2"
      },
      "outputs": [],
      "source": [
        "t_model, t_loss = training(300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXtQNyjcddP3"
      },
      "outputs": [],
      "source": [
        "results = [] # array for res\n",
        "model.eval() # set model to eval mode, disables dropout\n",
        "\n",
        "# testing loop\n",
        "for images, labels in test_loader:\n",
        "    images = images.to(device).float() # load onto device with correct data type\n",
        "    labels = labels.to(device).float()\n",
        "\n",
        "    predictions = model(images) # make predections on image in model\n",
        "    preds_1_0 = torch.where(predictions>0.5, 1, 0)\n",
        "    correct = (preds_1_0 == labels)\n",
        "    results.append(correct.detach().cpu().numpy().mean())\n",
        "\n",
        "    precision = BinaryPrecision().to(device) # binary percison\n",
        "    result = precision(preds_1_0.squeeze(), labels)\n",
        "\n",
        "\n",
        "accuracy = np.array(results).mean()\n",
        "print(accuracy)\n",
        "print(f\"Binary Precision: {result}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}