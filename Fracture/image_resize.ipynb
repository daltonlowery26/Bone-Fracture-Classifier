{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### resize images so they are a uniform size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "from PIL import Image as img\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# set wd\n",
    "os.chdir('C:/Users/dalto/OneDrive/Pictures/Documents/Projects/PyTorch/Fracture/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder emptied successfully\n",
      "Folder emptied successfully\n"
     ]
    }
   ],
   "source": [
    "# empty folders to avoid duplicates as there has been a few iterations of naming schemes used\n",
    "# empty the folder\n",
    "\n",
    "try:\n",
    "    shutil.rmtree('./images/fracture_resize')\n",
    "    # recreate the empty directory\n",
    "    os.makedirs('./images/fracture_resize')\n",
    "    print(\"Folder emptied successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {e}\")\n",
    "\n",
    "# empty the folder\n",
    "try:\n",
    "    shutil.rmtree('./images/non_fractured_resize')\n",
    "    # recreate the empty directory\n",
    "    os.makedirs('./images/non_fractured_resize')\n",
    "    print(\"Folder emptied successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing IMG0004028.jpg, skipping...\n",
      "Error processing IMG0004029.jpg, skipping...\n",
      "Error processing IMG0004036.jpg, skipping...\n",
      "Error processing IMG0004070.jpg, skipping...\n",
      "Error processing IMG0004073.jpg, skipping...\n",
      "Error processing IMG0004076.jpg, skipping...\n",
      "Error processing IMG0004079.jpg, skipping...\n",
      "Error processing IMG0004084.jpg, skipping...\n",
      "Error processing IMG0004092.jpg, skipping...\n",
      "Error processing IMG0004098.jpg, skipping...\n",
      "Error processing IMG0004100.jpg, skipping...\n",
      "Error processing IMG0004109.jpg, skipping...\n",
      "Error processing IMG0004119.jpg, skipping...\n",
      "Error processing IMG0004120.jpg, skipping...\n",
      "Error processing IMG0004121.jpg, skipping...\n",
      "Error processing IMG0004122.jpg, skipping...\n",
      "Error processing IMG0004123.jpg, skipping...\n",
      "Error processing IMG0004129.jpg, skipping...\n",
      "Error processing IMG0004130.jpg, skipping...\n",
      "Error processing IMG0004134.jpg, skipping...\n",
      "Error processing IMG0004142.jpg, skipping...\n",
      "Error processing IMG0004143.jpg, skipping...\n",
      "Error processing IMG0004145.jpg, skipping...\n",
      "Error processing IMG0004148.jpg, skipping...\n",
      "Error processing IMG0004149.jpg, skipping...\n",
      "Error processing IMG0004154.jpg, skipping...\n",
      "Error processing IMG0004155.jpg, skipping...\n",
      "Error processing IMG0004159.jpg, skipping...\n",
      "Error processing IMG0004169.jpg, skipping...\n",
      "Error processing IMG0004170.jpg, skipping...\n",
      "Error processing IMG0004173.jpg, skipping...\n",
      "Error processing IMG0004174.jpg, skipping...\n",
      "Error processing IMG0004177.jpg, skipping...\n",
      "Error processing IMG0004189.jpg, skipping...\n",
      "Error processing IMG0004194.jpg, skipping...\n",
      "Error processing IMG0004226.jpg, skipping...\n",
      "Error processing IMG0004227.jpg, skipping...\n",
      "Error processing IMG0004228.jpg, skipping...\n",
      "Error processing IMG0004251.jpg, skipping...\n",
      "Error processing IMG0004252.jpg, skipping...\n",
      "Error processing IMG0004255.jpg, skipping...\n",
      "Error processing IMG0004256.jpg, skipping...\n",
      "Error processing IMG0004258.jpg, skipping...\n",
      "Error processing IMG0004259.jpg, skipping...\n",
      "Error processing IMG0004263.jpg, skipping...\n",
      "Error processing IMG0004273.jpg, skipping...\n",
      "Error processing IMG0004275.jpg, skipping...\n",
      "Error processing IMG0004278.jpg, skipping...\n",
      "Error processing IMG0004279.jpg, skipping...\n",
      "Error processing IMG0004285.jpg, skipping...\n",
      "Error processing IMG0004286.jpg, skipping...\n",
      "Error processing IMG0004288.jpg, skipping...\n",
      "Error processing IMG0004290.jpg, skipping...\n",
      "Error processing IMG0004291.jpg, skipping...\n",
      "Error processing IMG0004297.jpg, skipping...\n",
      "Error processing IMG0004298.jpg, skipping...\n",
      "Error processing IMG0004304.jpg, skipping...\n",
      "Error processing IMG0004308.jpg, skipping...\n",
      "Error processing IMG0004347.jpg, skipping...\n"
     ]
    }
   ],
   "source": [
    "# Resize the images to 224x224, which is the most common size of images. \n",
    "# Images that are not this size also only have to downscale which is more optimal\n",
    "# Also added more details to the file name to make sure everyname was unqiue\n",
    "\n",
    "# function to resize\n",
    "def resize(imagePath, targetSize, save_folder, type):\n",
    "    # open and resize\n",
    "    image = img.open(imagePath)\n",
    "    image = image.resize(targetSize)\n",
    "    \n",
    "    # get base filename and add type to ensure unique file names\n",
    "    base_name = os.path.splitext(os.path.basename(imagePath))[0]  # get filename without extension\n",
    "    extension = os.path.splitext(imagePath)[1]  # get extension\n",
    "    new_name = f\"{base_name}_{type}{extension}\"\n",
    "    \n",
    "    # save the new image \n",
    "    save_path = os.path.join(save_folder, new_name)\n",
    "    image.save(save_path) \n",
    "    \n",
    "\n",
    "# iterate over elements in folder | no need here, all images are fine\n",
    "for filename in os.listdir('./images/original_data/Fractured'):\n",
    "    file_path = os.path.join('./images/original_data/Fractured', filename)\n",
    "    resize(file_path, (224,224), './images/fracture_resize', \"frac\")\n",
    "\n",
    "# had to implement try and except because a few images were corrupted in this folder \n",
    "for filename in os.listdir('./images/original_data/Non_fractured'):\n",
    "    try:\n",
    "        file_path = os.path.join('./images/original_data/Non_fractured', filename)\n",
    "        resize(file_path, (224,224),'./images/non_fractured_resize', \"nfrac\")\n",
    "    except:\n",
    "        # if there's a file error, print the error and continue\n",
    "        print(f\"Error processing {filename}, skipping...\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageOps\n",
    "\n",
    "def convert_to_grayscale(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        image = img.open(file_path)\n",
    "        \n",
    "        # Check if image is RGB (3 channels)\n",
    "        if image.mode == 'RGB':\n",
    "            # Convert to grayscale\n",
    "            gray_image = ImageOps.grayscale(image)\n",
    "            # Save back to the same location\n",
    "            gray_image.save(file_path)\n",
    "            print(f\"{image} converted to greyscale\")\n",
    "\n",
    "# Convert images in both folders\n",
    "convert_to_grayscale('./images/fracture_resize')\n",
    "convert_to_grayscale('./images/non_fractured_resize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a matching csv to prep for pytorch data loading\n",
    "data = {'name': [], 'class': []}\n",
    "\n",
    "# iterate over file names in fracture images\n",
    "for filename in os.listdir('./images/fracture_resize'):\n",
    "    data['name'].append(filename)\n",
    "    data['class'].append(1) # FRACTURE = 1\n",
    "\n",
    "for filename in os.listdir('./images/non_fractured_resize'):\n",
    "    data['name'].append(filename)\n",
    "    data['class'].append(0) # NO FRACTURE = 0\n",
    "\n",
    "# create dataframe\n",
    "class_id = pd.DataFrame(data)\n",
    "class_id.to_csv('./images/class_ids.csv', index=False) # note the slight class imbalance that potentially needs to be accounted for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new resize_data directory\n",
      "Total images in resize_data: 6151\n"
     ]
    }
   ],
   "source": [
    "# create a new directory for combined data\n",
    "try:\n",
    "    shutil.rmtree('./images/resize_data')\n",
    "    os.makedirs('./images/resize_data')\n",
    "    print(\"Created new resize_data directory\")\n",
    "except Exception as e:\n",
    "    os.makedirs('./images/resize_data', exist_ok=True)\n",
    "    print(\"Using existing resize_data directory\")\n",
    "\n",
    "# copy fracture images\n",
    "for img_file in os.listdir('./images/fracture_resize'):\n",
    "    src = os.path.join('./images/fracture_resize', img_file)\n",
    "    dst = os.path.join('./images/resize_data', img_file)\n",
    "    shutil.copy2(src, dst)\n",
    "\n",
    "# copy non-fracture images\n",
    "for img_file in os.listdir('./images/non_fractured_resize'):\n",
    "    src = os.path.join('./images/non_fractured_resize', img_file)\n",
    "    dst = os.path.join('./images/resize_data', img_file)\n",
    "    shutil.copy2(src, dst)\n",
    "\n",
    "print(f\"Total images in resize_data: {len(os.listdir('./images/resize_data'))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
